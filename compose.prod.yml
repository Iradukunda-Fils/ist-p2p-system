# ============================================================================
# P2P Procurement System - Production Docker Compose
# ============================================================================
# Optimized for production with security, performance, and reliability
# ============================================================================

services:
  # ========================================================================
  # PostgreSQL Database - Production
  # ========================================================================
  db:
    image: postgres:16-alpine
    container_name: p2p_postgres_prod
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/backups:/backups:ro
    environment:
      POSTGRES_DB: ${DATABASE_NAME:-p2p_procurement_prod}
      POSTGRES_USER: ${DATABASE_USER:-p2p_admin}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      PGDATA: /var/lib/postgresql/data
    # No exposed ports in production - internal access only
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U \"$POSTGRES_USER\" -d \"$POSTGRES_DB\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - db_network
    restart: always
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=512MB
      -c effective_cache_size=2GB
      -c maintenance_work_mem=128MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c timezone=UTC
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ========================================================================
  # Redis Cache & Message Broker - Production
  # ========================================================================
  redis:
    image: redis:7-alpine
    container_name: p2p_redis_prod
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    # No exposed ports in production
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - db_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # ========================================================================
  # Django Backend - Production
  # ========================================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: p2p_backend_prod
    command: >
      gunicorn
      --bind 0.0.0.0:8000
      --workers ${GUNICORN_WORKERS:-4}
      --worker-class ${GUNICORN_WORKER_CLASS:-sync}
      --timeout ${GUNICORN_TIMEOUT:-300}
      --max-requests ${GUNICORN_MAX_REQUESTS:-1000}
      --max-requests-jitter ${GUNICORN_MAX_REQUESTS_JITTER:-50}
      --access-logfile /app/logs/access.log
      --error-logfile /app/logs/error.log
      --log-level ${LOG_LEVEL:-info}
      --preload
      --chdir /app/src
    expose:
      - "8000"
    networks:
      - app_network
      - db_network
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health/', timeout=5)\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ========================================================================
  # Celery Worker - Production
  # ========================================================================
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: p2p_celery_worker_prod
    command: >
      celery -A config worker
      --loglevel=${CELERY_WORKER_LOG_LEVEL:-info}
      --concurrency=${CELERY_WORKER_CONCURRENCY:-4}
      --max-tasks-per-child=1000
      --time-limit=300
      --soft-time-limit=240
    volumes:
      - ./backend/keys:/app/keys:ro
      - media_files:/app/media
      - backend_logs:/app/logs
    environment: *backend_env_prod
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    networks:
      - app_network
      - db_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # ========================================================================
  # Celery Beat - Production
  # ========================================================================
  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: p2p_celery_beat_prod
    command: celery -A config beat --loglevel=${CELERY_BEAT_LOG_LEVEL:-info} --pidfile=/tmp/celerybeat.pid
    volumes:
      - ./backend/keys:/app/keys:ro
      - backend_logs:/app/logs
    environment: *backend_env_prod
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    networks:
      - app_network
      - db_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # ========================================================================
  # React Frontend - Production
  # ========================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: runtime
      args:
        VITE_API_BASE_URL: ${VITE_API_BASE_URL}
        VITE_APP_TITLE: ${VITE_APP_TITLE:-P2P Procurement System}
    container_name: p2p_frontend_prod
    expose:
      - "3000"
    networks:
      - app_network
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # ========================================================================
  # Nginx Gateway - Production
  # ========================================================================
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    container_name: p2p_nginx_gateway_prod
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_healthy
    networks:
      - app_network
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    volumes:
      - nginx_logs:/var/log/nginx
      - ./nginx/ssl:/etc/nginx/ssl:ro  # SSL certificates
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # ========================================================================
  # Log Aggregation (Optional)
  # ========================================================================
  logrotate:
    image: alpine:3.18
    container_name: p2p_logrotate
    command: >
      sh -c "
      apk add --no-cache logrotate &&
      echo '
      /var/log/nginx/*.log {
        daily
        missingok
        rotate 30
        compress
        delaycompress
        notifempty
        copytruncate
      }
      /var/log/backend/*.log {
        daily
        missingok
        rotate 30
        compress
        delaycompress
        notifempty
        copytruncate
      }
      ' > /etc/logrotate.d/app &&
      while true; do
        logrotate -f /etc/logrotate.d/app
        sleep 86400
      done
      "
    volumes:
      - nginx_logs:/var/log/nginx
      - backend_logs:/var/log/backend
    restart: always
    profiles:
      - logging

# ============================================================================
# Volumes
# ============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  static_files:
    driver: local
  media_files:
    driver: local
  backend_logs:
    driver: local
  nginx_logs:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  app_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16
  
  # Isolated network for database - production security
  db_network:
    driver: bridge
    internal: true  # No external access in production