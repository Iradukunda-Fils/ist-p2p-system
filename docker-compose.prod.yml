# ============================================================================
# P2P Procurement System - Production Docker Compose
# ============================================================================
# Optimized for production with security, performance, and reliability
# ============================================================================

services:
  # ========================================================================
  # PostgreSQL Database - Production
  # ========================================================================
  db:
    image: postgres:16-alpine
    container_name: p2p_postgres_prod
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/backups:/backups:ro
    environment:
      POSTGRES_DB: ${DATABASE_NAME:-p2p_procurement_prod}
      POSTGRES_USER: ${DATABASE_USER:-p2p_admin}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8"
    # No exposed ports in production - internal access only
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DATABASE_USER} -d ${DATABASE_NAME}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - db_network
    restart: always
    command: 
      - "postgres"
      - "-c"
      - "max_connections=200"
      - "-c"
      - "shared_buffers=512MB"
      - "-c"
      - "effective_cache_size=2GB"
      - "-c"
      - "maintenance_work_mem=128MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "default_statistics_target=100"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "effective_io_concurrency=200"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ========================================================================
  # Redis Cache & Message Broker - Production
  # ========================================================================
  redis:
    image: redis:7-alpine
    container_name: p2p_redis_prod
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - redis_data:/data
    # No exposed ports in production
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - app_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # ========================================================================
  # Django Backend - Production
  # ========================================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: p2p_backend_prod
    command: >
      gunicorn
      --bind 0.0.0.0:8000
      --workers ${GUNICORN_WORKERS:-4}
      --worker-class ${GUNICORN_WORKER_CLASS:-sync}
      --timeout ${GUNICORN_TIMEOUT:-300}
      --max-requests ${GUNICORN_MAX_REQUESTS:-1000}
      --max-requests-jitter ${GUNICORN_MAX_REQUESTS_JITTER:-50}
      --access-logfile /app/logs/access.log
      --error-logfile /app/logs/error.log
      --log-level ${LOG_LEVEL:-info}
      --preload
      --chdir /app/src
      config.wsgi:application
    volumes:
      - ./backend/keys:/app/keys:ro
      - static_files:/app/static
      - media_files:/app/media
      - backend_logs:/app/logs
    environment: &backend_env_prod
      # Django settings - PRODUCTION
      DJANGO_SETTINGS_MODULE: config.settings.production
      SECRET_KEY: ${SECRET_KEY}
      DEBUG: False
      ALLOWED_HOSTS: ${ALLOWED_HOSTS}
      ENVIRONMENT: production
      
      # Database URL (PostgreSQL) - Single URL instead of multiple variables
      DATABASE_URL: ${DATABASE_URL}
      
      # Redis URLs - Simplified to just URLs
      REDIS_URL: ${REDIS_URL}
      CACHE_URL: ${CACHE_URL}
      CELERY_BROKER_URL: ${CELERY_BROKER_URL}
      CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND}
      
      # CORS
      CORS_ALLOWED_ORIGINS: ${CORS_ALLOWED_ORIGINS}
      
      # File Storage
      STATIC_ROOT: /app/static
      MEDIA_ROOT: /app/media
      MAX_UPLOAD_SIZE: ${MAX_UPLOAD_SIZE:-52428800}
      
      # AWS S3 (if using cloud storage)
      USE_S3: ${USE_S3:-False}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:-}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:-}
      AWS_STORAGE_BUCKET_NAME: ${AWS_STORAGE_BUCKET_NAME:-}
      AWS_S3_REGION_NAME: ${AWS_S3_REGION_NAME:-}
      
      # Email
      EMAIL_BACKEND: ${EMAIL_BACKEND:-django.core.mail.backends.smtp.EmailBackend}
      EMAIL_HOST: ${EMAIL_HOST:-}
      EMAIL_PORT: ${EMAIL_PORT:-587}
      EMAIL_USE_TLS: ${EMAIL_USE_TLS:-True}
      EMAIL_HOST_USER: ${EMAIL_HOST_USER:-}
      EMAIL_HOST_PASSWORD: ${EMAIL_HOST_PASSWORD:-}
      DEFAULT_FROM_EMAIL: ${DEFAULT_FROM_EMAIL:-noreply@p2p.com}
      
      # Logging
      DJANGO_LOG_LEVEL: ${DJANGO_LOG_LEVEL:-INFO}
      SQL_LOG_LEVEL: ${SQL_LOG_LEVEL:-WARNING}
      
      # Security - Production
      SESSION_COOKIE_SECURE: ${SESSION_COOKIE_SECURE:-True}
      CSRF_COOKIE_SECURE: ${CSRF_COOKIE_SECURE:-True}
      SECURE_SSL_REDIRECT: ${SECURE_SSL_REDIRECT:-True}
      SECURE_HSTS_SECONDS: ${SECURE_HSTS_SECONDS:-31536000}
      SECURE_HSTS_INCLUDE_SUBDOMAINS: ${SECURE_HSTS_INCLUDE_SUBDOMAINS:-True}
      SECURE_HSTS_PRELOAD: ${SECURE_HSTS_PRELOAD:-True}
      
      # Monitoring
      SENTRY_DSN: ${SENTRY_DSN:-}
      
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    expose:
      - "8000"
    networks:
      - app_network
      - db_network
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health/', timeout=5)\" || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ========================================================================
  # Celery Worker - Production
  # ========================================================================
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: p2p_celery_worker_prod
    command: >
      celery -A config worker
      --loglevel=${CELERY_WORKER_LOG_LEVEL:-info}
      --concurrency=${CELERY_WORKER_CONCURRENCY:-4}
      --max-tasks-per-child=1000
      --time-limit=300
      --soft-time-limit=240
    volumes:
      - ./backend/keys:/app/keys:ro
      - media_files:/app/media
      - backend_logs:/app/logs
    environment: *backend_env_prod
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    networks:
      - app_network
      - db_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # ========================================================================
  # Celery Beat - Production
  # ========================================================================
  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: p2p_celery_beat_prod
    command: celery -A config beat --loglevel=${CELERY_BEAT_LOG_LEVEL:-info} --pidfile=/tmp/celerybeat.pid
    volumes:
      - ./backend/keys:/app/keys:ro
      - backend_logs:/app/logs
    environment: *backend_env_prod
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started
    networks:
      - app_network
      - db_network
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # ========================================================================
  # React Frontend - Production
  # ========================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: runtime
      args:
        VITE_API_BASE_URL: ${VITE_API_BASE_URL}
        VITE_APP_TITLE: ${VITE_APP_TITLE:-P2P Procurement System}
    container_name: p2p_frontend_prod
    expose:
      - "3000"
    networks:
      - app_network
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # ========================================================================
  # Nginx Gateway - Production
  # ========================================================================
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile
    container_name: p2p_nginx_gateway_prod
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_healthy
    networks:
      - app_network
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    volumes:
      - nginx_logs:/var/log/nginx
      - ./nginx/ssl:/etc/nginx/ssl:ro  # SSL certificates
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # ========================================================================
  # Log Aggregation (Optional)
  # ========================================================================
  logrotate:
    image: alpine:3.18
    container_name: p2p_logrotate
    command: >
      sh -c "
      apk add --no-cache logrotate &&
      echo '
      /var/log/nginx/*.log {
        daily
        missingok
        rotate 30
        compress
        delaycompress
        notifempty
        copytruncate
      }
      /var/log/backend/*.log {
        daily
        missingok
        rotate 30
        compress
        delaycompress
        notifempty
        copytruncate
      }
      ' > /etc/logrotate.d/app &&
      while true; do
        logrotate -f /etc/logrotate.d/app
        sleep 86400
      done
      "
    volumes:
      - nginx_logs:/var/log/nginx
      - backend_logs:/var/log/backend
    restart: always
    profiles:
      - logging

# ============================================================================
# Volumes
# ============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  static_files:
    driver: local
  media_files:
    driver: local
  backend_logs:
    driver: local
  nginx_logs:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  app_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16
  
  # Isolated network for database - production security
  db_network:
    driver: bridge
    internal: true  # No external access in production